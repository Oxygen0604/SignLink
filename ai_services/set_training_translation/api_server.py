"""
ç”Ÿäº§çº§æ‰‹è¯­è¯†åˆ« API æœåŠ¡
- æ ‡å‡† RESTful API è®¾è®¡
- å®Œæ•´çš„é”™è¯¯å¤„ç†
- è¯·æ±‚æ—¥å¿—è®°å½•
- æ”¯æŒè·¨åŸŸè®¿é—® (CORS)
- å¥åº·æ£€æŸ¥ç«¯ç‚¹
- API æ–‡æ¡£
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import cv2
import numpy as np
import mediapipe as mp
import tensorflow as tf
from tensorflow import keras
import json
import base64
from io import BytesIO
from PIL import Image
import os
import logging
from datetime import datetime
from functools import wraps
import traceback

# ============================================================================
# é…ç½®éƒ¨åˆ†
# ============================================================================

# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(BASE_DIR, 'api_server.log')),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Flask åº”ç”¨é…ç½®
app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False  # æ”¯æŒä¸­æ–‡
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # é™åˆ¶ä¸Šä¼ æ–‡ä»¶æœ€å¤§ 16MB

# CORS é…ç½® - å…è®¸æ‰€æœ‰æ¥æºè®¿é—® (ç”Ÿäº§ç¯å¢ƒåº”è¯¥é™åˆ¶ç‰¹å®šåŸŸå)
CORS(app, resources={
    r"/api/*": {
        "origins": "*",  # ç”Ÿäº§ç¯å¢ƒæ”¹ä¸ºå…·ä½“åŸŸåï¼Œå¦‚ ["https://yourdomain.com"]
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type", "Authorization"]
    }
})

# ============================================================================
# æ‰‹è¯­è¯†åˆ«æ ¸å¿ƒç±»
# ============================================================================

class SignLanguageRecognizer:
    """æ‰‹è¯­è¯†åˆ«å™¨ - å°è£…æ¨¡å‹å’Œé¢„å¤„ç†é€»è¾‘"""
    
    def __init__(self, model_path, label_path):
        """
        åˆå§‹åŒ–è¯†åˆ«å™¨
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„ (.h5)
            label_path: æ ‡ç­¾æ–‡ä»¶è·¯å¾„ (.json)
        """
        logger.info(f"åŠ è½½æ¨¡å‹: {model_path}")
        self.model = keras.models.load_model(model_path)
        
        logger.info(f"åŠ è½½æ ‡ç­¾: {label_path}")
        with open(label_path, 'r', encoding='utf-8') as f:
            label_mapping = json.load(f)
        self.labels = label_mapping['classes']
        
        # åˆå§‹åŒ– MediaPipe æ‰‹éƒ¨æ£€æµ‹
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=2,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils
        
        logger.info(f"æ¨¡å‹åŠ è½½æˆåŠŸï¼Œæ”¯æŒ {len(self.labels)} ä¸ªç±»åˆ«: {self.labels}")
    
    def extract_features(self, image):
        """
        æå–æ‰‹éƒ¨å…³é”®ç‚¹ç‰¹å¾
        
        Args:
            image: OpenCV æ ¼å¼çš„å›¾åƒ (BGR)
            
        Returns:
            features: 126ç»´ç‰¹å¾å‘é‡ï¼Œå¦‚æœæœªæ£€æµ‹åˆ°æ‰‹éƒ¨åˆ™è¿”å› None
            hand_landmarks: MediaPipe æ‰‹éƒ¨å…³é”®ç‚¹å¯¹è±¡
        """
        # è½¬æ¢ä¸º RGB (MediaPipe éœ€è¦)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # æ‰‹éƒ¨æ£€æµ‹
        results = self.hands.process(image_rgb)
        
        if not results.multi_hand_landmarks:
            return None, None
        
        # æå–ç‰¹å¾å‘é‡
        features = []
        for hand_landmarks in results.multi_hand_landmarks:
            hand_features = []
            for landmark in hand_landmarks.landmark:
                hand_features.extend([landmark.x, landmark.y, landmark.z])
            features.extend(hand_features)
        
        # å¡«å……åˆ°å›ºå®šé•¿åº¦ (å•æ‰‹63ç»´ï¼ŒåŒæ‰‹126ç»´)
        if len(results.multi_hand_landmarks) == 1:
            features.extend([0] * 63)
        
        return np.array(features[:126]), results.multi_hand_landmarks
    
    def predict(self, image, return_all_probs=False):
        """
        é¢„æµ‹æ‰‹è¯­å«ä¹‰
        
        Args:
            image: OpenCV æ ¼å¼çš„å›¾åƒ (BGR)
            return_all_probs: æ˜¯å¦è¿”å›æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡
            
        Returns:
            dict: åŒ…å«é¢„æµ‹ç»“æœçš„å­—å…¸
        """
        # æå–ç‰¹å¾
        features, hand_landmarks = self.extract_features(image)
        
        if features is None:
            return {
                'detected': False,
                'message': 'æœªæ£€æµ‹åˆ°æ‰‹éƒ¨'
            }
        
        # æ¨¡å‹é¢„æµ‹
        features = features.reshape(1, -1)
        predictions = self.model.predict(features, verbose=0)[0]
        
        # è·å–é¢„æµ‹ç»“æœ
        predicted_class = int(np.argmax(predictions))
        confidence = float(predictions[predicted_class])
        predicted_label = self.labels[predicted_class]
        
        result = {
            'detected': True,
            'word': predicted_label,
            'confidence': confidence,
            'hand_landmarks': hand_landmarks
        }
        
        # å¦‚æœéœ€è¦è¿”å›æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡
        if return_all_probs:
            result['all_predictions'] = {
                self.labels[i]: float(predictions[i])
                for i in range(len(self.labels))
            }
        
        return result
    
    def draw_landmarks(self, image, hand_landmarks):
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶æ‰‹éƒ¨å…³é”®ç‚¹
        
        Args:
            image: OpenCV æ ¼å¼çš„å›¾åƒ (BGR)
            hand_landmarks: MediaPipe æ‰‹éƒ¨å…³é”®ç‚¹å¯¹è±¡
            
        Returns:
            image: ç»˜åˆ¶äº†å…³é”®ç‚¹çš„å›¾åƒ
        """
        for landmarks in hand_landmarks:
            self.mp_drawing.draw_landmarks(
                image,
                landmarks,
                self.mp_hands.HAND_CONNECTIONS,
                self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),
                self.mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)
            )
        return image

# ============================================================================
# å…¨å±€å˜é‡
# ============================================================================

recognizer = None  # å…¨å±€è¯†åˆ«å™¨å®ä¾‹
request_count = 0  # è¯·æ±‚è®¡æ•°
start_time = datetime.now()  # æœåŠ¡å¯åŠ¨æ—¶é—´

# ============================================================================
# è£…é¥°å™¨ - è¯·æ±‚æ—¥å¿—å’Œé”™è¯¯å¤„ç†
# ============================================================================

def log_request(f):
    """è®°å½• API è¯·æ±‚æ—¥å¿—"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        global request_count
        request_count += 1
        
        logger.info(f"è¯·æ±‚ #{request_count} - {request.method} {request.path} - IP: {request.remote_addr}")
        
        try:
            response = f(*args, **kwargs)
            return response
        except Exception as e:
            logger.error(f"è¯·æ±‚å¤„ç†å¤±è´¥: {str(e)}")
            logger.error(traceback.format_exc())
            return jsonify({
                'success': False,
                'error': str(e),
                'message': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'
            }), 500
    
    return decorated_function

# ============================================================================
# API è·¯ç”±
# ============================================================================

@app.route('/')
def index():
    """API æ ¹è·¯å¾„ - è¿”å› API æ–‡æ¡£"""
    return jsonify({
        'service': 'Sign Language Recognition API',
        'version': '1.0.0',
        'status': 'running',
        'endpoints': {
            'health': {
                'method': 'GET',
                'path': '/api/health',
                'description': 'å¥åº·æ£€æŸ¥'
            },
            'info': {
                'method': 'GET',
                'path': '/api/info',
                'description': 'è·å–æ¨¡å‹ä¿¡æ¯'
            },
            'predict': {
                'method': 'POST',
                'path': '/api/predict',
                'description': 'æ‰‹è¯­è¯†åˆ«',
                'body': {
                    'image': 'base64 ç¼–ç çš„å›¾åƒ (å¿…éœ€)',
                    'draw_landmarks': 'æ˜¯å¦ç»˜åˆ¶å…³é”®ç‚¹ (å¯é€‰, é»˜è®¤ false)',
                    'return_all_probs': 'æ˜¯å¦è¿”å›æ‰€æœ‰ç±»åˆ«æ¦‚ç‡ (å¯é€‰, é»˜è®¤ false)'
                }
            }
        },
        'documentation': 'https://github.com/yourusername/sign-language-api'
    })

@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    uptime = (datetime.now() - start_time).total_seconds()
    
    return jsonify({
        'status': 'healthy',
        'model_loaded': recognizer is not None,
        'uptime_seconds': uptime,
        'request_count': request_count,
        'timestamp': datetime.now().isoformat()
    })

@app.route('/api/info', methods=['GET'])
@log_request
def get_info():
    """è·å–æ¨¡å‹ä¿¡æ¯"""
    if recognizer is None:
        return jsonify({
            'success': False,
            'message': 'æ¨¡å‹æœªåŠ è½½'
        }), 503
    
    return jsonify({
        'success': True,
        'model_info': {
            'num_classes': len(recognizer.labels),
            'classes': recognizer.labels,
            'input_shape': [126],  # 126ç»´ç‰¹å¾å‘é‡
            'description': 'åŸºäº MediaPipe å’Œ TensorFlow çš„æ‰‹è¯­è¯†åˆ«æ¨¡å‹'
        }
    })

@app.route('/api/predict', methods=['POST'])
@log_request
def predict():
    """
    æ‰‹è¯­è¯†åˆ« API
    
    è¯·æ±‚ç¤ºä¾‹:
    {
        "image": "data:image/jpeg;base64,/9j/4AAQSkZJRg...",
        "draw_landmarks": true,
        "return_all_probs": false
    }
    
    å“åº”ç¤ºä¾‹:
    {
        "success": true,
        "detected": true,
        "word": "hello",
        "confidence": 0.92,
        "annotated_image": "data:image/jpeg;base64,..."
    }
    """
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
    if recognizer is None:
        return jsonify({
            'success': False,
            'message': 'æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆå¯åŠ¨æœåŠ¡'
        }), 503
    
    # æ£€æŸ¥è¯·æ±‚æ•°æ®
    if not request.json or 'image' not in request.json:
        return jsonify({
            'success': False,
            'message': 'è¯·æ±‚æ•°æ®æ ¼å¼é”™è¯¯ï¼Œéœ€è¦ JSON æ ¼å¼ä¸”åŒ…å« image å­—æ®µ'
        }), 400
    
    try:
        # è·å–å‚æ•°
        image_data = request.json['image']
        draw_landmarks = request.json.get('draw_landmarks', False)
        return_all_probs = request.json.get('return_all_probs', False)
        
        # è§£ç  base64 å›¾åƒ
        if ',' in image_data:
            image_data = image_data.split(',')[1]
        
        image_bytes = base64.b64decode(image_data)
        image = Image.open(BytesIO(image_bytes))
        image_np = np.array(image)
        
        # è½¬æ¢é¢œè‰²ç©ºé—´
        if len(image_np.shape) == 2:  # ç°åº¦å›¾
            image_np = cv2.cvtColor(image_np, cv2.COLOR_GRAY2BGR)
        elif image_np.shape[2] == 4:  # RGBA
            image_np = cv2.cvtColor(image_np, cv2.COLOR_RGBA2BGR)
        elif image_np.shape[2] == 3:  # RGB
            image_np = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
        
        # è°ƒç”¨è¯†åˆ«å™¨
        result = recognizer.predict(image_np, return_all_probs=return_all_probs)
        
        # å¦‚æœæœªæ£€æµ‹åˆ°æ‰‹éƒ¨
        if not result['detected']:
            return jsonify({
                'success': True,
                'detected': False,
                'message': result['message']
            })
        
        # æ„å»ºå“åº”
        response = {
            'success': True,
            'detected': True,
            'word': result['word'],
            'confidence': result['confidence']
        }
        
        # æ·»åŠ æ‰€æœ‰ç±»åˆ«æ¦‚ç‡
        if return_all_probs:
            response['all_predictions'] = result['all_predictions']
        
        # ç»˜åˆ¶å…³é”®ç‚¹
        if draw_landmarks and result['hand_landmarks']:
            image_np = recognizer.draw_landmarks(image_np, result['hand_landmarks'])
            
            # è½¬æ¢å› base64
            _, buffer = cv2.imencode('.jpg', image_np, [cv2.IMWRITE_JPEG_QUALITY, 85])
            annotated_image = base64.b64encode(buffer).decode('utf-8')
            response['annotated_image'] = f'data:image/jpeg;base64,{annotated_image}'
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"é¢„æµ‹å¤±è´¥: {str(e)}")
        logger.error(traceback.format_exc())
        return jsonify({
            'success': False,
            'message': f'é¢„æµ‹å¤±è´¥: {str(e)}'
        }), 500

@app.errorhandler(404)
def not_found(error):
    """404 é”™è¯¯å¤„ç†"""
    return jsonify({
        'success': False,
        'message': 'è¯·æ±‚çš„ç«¯ç‚¹ä¸å­˜åœ¨',
        'available_endpoints': [
            '/api/health',
            '/api/info',
            '/api/predict'
        ]
    }), 404

@app.errorhandler(413)
def request_entity_too_large(error):
    """è¯·æ±‚ä½“è¿‡å¤§é”™è¯¯å¤„ç†"""
    return jsonify({
        'success': False,
        'message': 'ä¸Šä¼ çš„å›¾åƒè¿‡å¤§ï¼Œæœ€å¤§æ”¯æŒ 16MB'
    }), 413

# ============================================================================
# æœåŠ¡å¯åŠ¨
# ============================================================================

def initialize_service():
    """åˆå§‹åŒ–æœåŠ¡ - åŠ è½½æ¨¡å‹"""
    global recognizer
    
    model_path = os.path.join(BASE_DIR, 'sign_language_model.h5')
    label_path = os.path.join(BASE_DIR, 'sign_language_labels.json')
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        logger.error(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return False
    
    if not os.path.exists(label_path):
        logger.error(f"æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨: {label_path}")
        return False
    
    try:
        recognizer = SignLanguageRecognizer(model_path, label_path)
        logger.info("âœ… æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        logger.error(f"âŒ æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        logger.error(traceback.format_exc())
        return False

if __name__ == '__main__':
    print("\n" + "="*70)
    print("ğŸš€ æ‰‹è¯­è¯†åˆ« API æœåŠ¡")
    print("="*70)
    
    # åˆå§‹åŒ–æœåŠ¡
    print("\nğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹...")
    if initialize_service():
        print("\nâœ… æœåŠ¡å¯åŠ¨æˆåŠŸï¼")
        print("\nğŸ“ API ç«¯ç‚¹:")
        print("   - å¥åº·æ£€æŸ¥:  http://localhost:5000/api/health")
        print("   - æ¨¡å‹ä¿¡æ¯:  http://localhost:5000/api/info")
        print("   - æ‰‹è¯­è¯†åˆ«:  http://localhost:5000/api/predict")
        print("\nğŸ“ API æ–‡æ¡£:   http://localhost:5000/")
        print("\nğŸ’¡ æç¤º:")
        print("   - æ‰€æœ‰ç«¯ç‚¹æ”¯æŒè·¨åŸŸè®¿é—® (CORS)")
        print("   - æ—¥å¿—ä¿å­˜åœ¨: api_server.log")
        print("   - ä½¿ç”¨ Ctrl+C åœæ­¢æœåŠ¡")
        print("="*70 + "\n")
        
        # å¯åŠ¨ Flask æœåŠ¡
        app.run(
            host='0.0.0.0',  # å…è®¸å¤–éƒ¨è®¿é—®
            port=5000,
            debug=False,      # ç”Ÿäº§ç¯å¢ƒå…³é—­ debug
            threaded=True     # æ”¯æŒå¤šçº¿ç¨‹
        )
    else:
        print("\nâŒ æœåŠ¡å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        print("="*70 + "\n")
