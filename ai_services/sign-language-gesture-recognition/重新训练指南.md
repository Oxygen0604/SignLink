# 重新训练模型指南

## 📖 概述

本文档详细说明如何在增加或减少训练数据后重新训练手语手势识别模型。

## 🎯 适用场景

- ✅ 添加新的手势类别
- ✅ 增加现有类别的训练样本
- ✅ 删除某些类别
- ✅ 更新训练数据
- ✅ 使用全新的数据集

---

## 📁 第一步: 准备训练数据

### 1.1 数据文件夹结构

训练和测试视频必须按以下结构组织：

```
train_videos/
├── 手势类别1/
│   ├── video1.mp4
│   ├── video2.mp4
│   ├── video3.mp4
│   └── ...
├── 手势类别2/
│   ├── video1.mp4
│   ├── video2.mp4
│   └── ...
└── 手势类别3/
    ├── video1.mp4
    └── ...

test_videos/
├── 手势类别1/
│   ├── test_video1.mp4
│   └── ...
├── 手势类别2/
│   └── ...
└── 手势类别3/
    └── ...
```

### 1.2 数据要求

- **视频格式**: 支持 .mp4, .avi, .mov 等常见格式
- **建议样本数**: 每个类别至少 3-5 个训练视频，2-3 个测试视频
- **视频质量**: 清晰、光线充足、手势完整
- **命名规范**: 文件名可以任意，但要放在对应类别的文件夹中

### 1.3 实际示例

#### 场景 A: 添加新手势类别

假设您想添加 "Hello" 和 "Thank You" 两个新手势：

```bash
# 1. 在 train_videos 中创建新文件夹
mkdir train_videos/Hello
mkdir train_videos/ThankYou

# 2. 放入训练视频
# train_videos/Hello/hello_001.mp4
# train_videos/Hello/hello_002.mp4
# train_videos/Hello/hello_003.mp4
# train_videos/ThankYou/thankyou_001.mp4
# ...

# 3. 在 test_videos 中创建对应文件夹
mkdir test_videos/Hello
mkdir test_videos/ThankYou

# 4. 放入测试视频
```

#### 场景 B: 增加现有类别的样本

假设您想为 "Accept" 添加更多训练样本：

```bash
# 直接将新视频放入现有文件夹
# train_videos/Accept/050_004_001.mp4
# train_videos/Accept/050_005_001.mp4
# ...
```

#### 场景 C: 删除某个类别

假设您想删除 "Appear" 类别：

```bash
# Windows
rmdir /s train_videos\Appear
rmdir /s test_videos\Appear

# 或者在文件资源管理器中直接删除文件夹
```

---

## 🔄 第二步: 清理旧的训练数据

在重新训练之前，需要清理之前的训练产物。

### ⚡ 方式 A: 直接覆盖（不需要备份）

**如果您不需要保留旧模型**，只需要删除帧文件和特征文件即可。训练时会**自动覆盖**旧的模型文件。

```powershell
# 删除旧的训练帧（必须删除！）
Remove-Item -Recurse -Force train_frames -ErrorAction SilentlyContinue

# 删除旧的测试帧（必须删除！）
Remove-Item -Recurse -Force test_frames -ErrorAction SilentlyContinue

# 删除旧的特征文件（建议删除）
Remove-Item predicted-frames-final_result-train.pkl -ErrorAction SilentlyContinue
Remove-Item predicted-frames-final_result-test.pkl -ErrorAction SilentlyContinue
```

**说明：**

- ✅ **CNN 模型** (`gesture_model_best.h5`) - 训练时会自动覆盖
- ✅ **RNN 模型** (`checkpoints/gesture_rnn.h5`) - 训练时会自动覆盖
- ✅ **标签文件** (`retrained_labels.txt`) - 训练时会自动更新
- ⚠️ **帧文件夹** - 必须手动删除，否则会与新数据混在一起
- ⚠️ **特征文件** - 建议删除，否则可能与新数据不匹配

### 🛡️ 方式 B: 先备份再训练（推荐谨慎用户）

**如果您想保留旧模型**作为备份，防止新训练失败：

```powershell
# 创建备份文件夹
mkdir models_backup -ErrorAction SilentlyContinue

# 备份CNN模型
Copy-Item gesture_model_best.h5 models_backup/gesture_model_best_backup.h5 -ErrorAction SilentlyContinue

# 备份RNN模型
Copy-Item checkpoints/gesture_rnn.h5 models_backup/gesture_rnn_backup.h5 -ErrorAction SilentlyContinue

# 备份标签文件
Copy-Item retrained_labels.txt models_backup/retrained_labels_backup.txt -ErrorAction SilentlyContinue

# 然后执行方式A的清理命令
Remove-Item -Recurse -Force train_frames -ErrorAction SilentlyContinue
Remove-Item -Recurse -Force test_frames -ErrorAction SilentlyContinue
Remove-Item predicted-frames-*.pkl -ErrorAction SilentlyContinue
```

---

## 🚀 第三步: 重新训练完整流程

### 3.1 提取视频帧

```powershell
# 从训练视频提取帧
python video-to-frame.py train_videos train_frames

# 从测试视频提取帧
python video-to-frame.py test_videos test_frames
```

**预期输出:**

```
Source Directory containing gestures: ...\train_videos
Destination Directory containing frames: ...\train_frames

100%|████████████████████| 处理进度条
```

**检查点:**

- 确认 `train_frames` 文件夹中为每个类别创建了子文件夹
- 每个子文件夹包含提取的 .jpeg 帧文件

---

### 3.2 训练 CNN 模型

```powershell
python retrain_tf2.py --image_dir train_frames --epochs 15
```

**可选参数:**

```powershell
# 调整训练轮数
python retrain_tf2.py --image_dir train_frames --epochs 20

# 调整批大小（内存较小时使用较小值）
python retrain_tf2.py --image_dir train_frames --batch_size 16 --epochs 15

# 指定输出模型名称
python retrain_tf2.py --image_dir train_frames --output_model my_gesture_model --epochs 15
```

**训练时长估计:**

- 2 个类别，每类 600 帧：约 2-3 分钟/epoch
- 5 个类别，每类 600 帧：约 5-7 分钟/epoch

**预期输出:**

```
Creating datasets...
Found N classes: ['类别1', '类别2', ...]
Training samples: XXX
Validation samples: XXX

Epoch 1/15
...
val_accuracy: 0.98xx

Model saved to gesture_model_best.h5
```

**检查点:**

- 验证准确率应该达到 90% 以上
- 生成了 `gesture_model_best.h5` 文件
- 生成了 `retrained_labels.txt` 文件（包含所有类别名称）

---

### 3.3 提取训练集特征

```powershell
python predict_spatial_tf2.py gesture_model_best.h5 train_frames --batch_size 100
```

**预期输出:**

```
Loading model from gesture_model_best.h5...
Model loaded successfully!

Found N gesture classes: [...]

Processing XXX frames from '类别1'...
100%|████████████████████| 进度条
...

Saved XXXX predictions
Done!
```

**生成文件:**

- `predicted-frames-final_result-train.pkl`

---

### 3.4 提取测试集特征

```powershell
python predict_spatial_tf2.py gesture_model_best.h5 test_frames --batch_size 100 --test
```

**注意:** `--test` 参数很重要！它会生成测试集的特征文件。

**生成文件:**

- `predicted-frames-final_result-test.pkl`

---

### 3.5 训练 RNN 模型

```powershell
python rnn_train_tf2.py predicted-frames-final_result-train.pkl gesture_rnn.model --batch_size 32 --epochs 20
```

**可选参数:**

```powershell
# 使用不同的架构
python rnn_train_tf2.py predicted-frames-final_result-train.pkl gesture_rnn.model --model_type wide --epochs 20

# 可选架构类型:
# --model_type default  (标准LSTM, 2层128单元)
# --model_type wide     (宽LSTM, 1层256单元) [推荐]
# --model_type deep     (深LSTM, 3层64单元)

# 调整训练轮数
python rnn_train_tf2.py predicted-frames-final_result-train.pkl gesture_rnn.model --epochs 30
```

**预期输出:**

```
Loading data from predicted-frames-final_result-train.pkl...

Class Name      Numeric Label
类别1          0
类别2          1
...

Dataset shape: (XX, 201, N)
Input size per frame: N

Creating wide RNN model...
Training model for 20 epochs...

Epoch 1/20
...
val_accuracy: 0.9xxx

Model saved to checkpoints\gesture_rnn.h5
```

**检查点:**

- 验证准确率应该达到 85% 以上
- 生成了 `checkpoints/gesture_rnn.h5` 文件

---

### 3.6 评估模型

```powershell
python rnn_eval_tf2.py predicted-frames-final_result-test.pkl gesture_rnn.model
```

**预期输出:**

```
Test Accuracy: X/Y = ZZ.ZZ%

==================================================
EVALUATION SUMMARY
==================================================
Video 1: 预测类别 (confidence: 0.XXXX) | Actual: 实际类别 | ✓
...
```

**生成文件:**

- `results.txt` (详细的测试结果)

**检查点:**

- 查看测试准确率是否满意
- 检查 `results.txt` 了解每个视频的预测情况

---

## 📊 第四步: 验证新模型

### 4.1 测试单个视频

```powershell
# 测试某个测试集视频
python predict_video.py test_videos/类别名/视频文件.mp4

# 测试训练集视频（应该预测正确）
python predict_video.py train_videos/类别名/视频文件.mp4
```

### 4.2 批量测试

创建一个测试脚本来测试所有测试视频：

```powershell
# 测试 Accept 类别的所有视频
Get-ChildItem test_videos/Accept/*.mp4 | ForEach-Object {
    Write-Host "`n测试: $($_.Name)"
    python predict_video.py $_.FullName
}
```

---

## ⚠️ 常见问题和解决方案

### 问题 1: 训练准确率很低

**可能原因:**

- 训练样本太少
- 类别之间手势相似度高
- 视频质量差

**解决方案:**

```powershell
# 1. 增加训练轮数
python retrain_tf2.py --image_dir train_frames --epochs 25

# 2. 尝试不同的批大小
python retrain_tf2.py --image_dir train_frames --batch_size 16 --epochs 20

# 3. 检查数据质量，移除模糊或错误的视频
```

### 问题 2: 某个类别识别率低

**解决方案:**

1. 为该类别添加更多训练样本
2. 确保该类别的手势与其他类别有明显区别
3. 检查视频质量和光线条件

### 问题 3: 内存不足

**解决方案:**

```powershell
# 减小批大小
python retrain_tf2.py --image_dir train_frames --batch_size 8 --epochs 15
python rnn_train_tf2.py predicted-frames-final_result-train.pkl gesture_rnn.model --batch_size 16
```

### 问题 4: 模型过拟合

**表现:** 训练准确率很高，但测试准确率低

**解决方案:**

1. 增加更多训练数据
2. 使用数据增强
3. 减少训练轮数
4. 添加更多 dropout

---

## 📝 完整示例：添加 3 个新手势

假设您要添加 "Hello", "Goodbye", "Please" 三个新手势：

### 步骤详解

```powershell
# 1. 准备数据（手动操作）
# 将视频放入对应文件夹:
# train_videos/Hello/
# train_videos/Goodbye/
# train_videos/Please/
# test_videos/Hello/
# test_videos/Goodbye/
# test_videos/Please/

# 2. 清理旧数据（模型文件会自动覆盖，只需删除帧和特征）
Remove-Item -Recurse -Force train_frames -ErrorAction SilentlyContinue
Remove-Item -Recurse -Force test_frames -ErrorAction SilentlyContinue
Remove-Item predicted-frames-final_result-train.pkl -ErrorAction SilentlyContinue
Remove-Item predicted-frames-final_result-test.pkl -ErrorAction SilentlyContinue

# 3. 提取帧
python video-to-frame.py train_videos train_frames
python video-to-frame.py test_videos test_frames

# 4. 训练CNN（自动覆盖 gesture_model_best.h5）
python retrain_tf2.py --image_dir train_frames --epochs 15

# 5. 提取特征
python predict_spatial_tf2.py gesture_model_best.h5 train_frames --batch_size 100
python predict_spatial_tf2.py gesture_model_best.h5 test_frames --batch_size 100 --test

# 6. 训练RNN（自动覆盖 checkpoints/gesture_rnn.h5）
python rnn_train_tf2.py predicted-frames-final_result-train.pkl gesture_rnn.model --batch_size 32 --epochs 20

# 7. 评估
python rnn_eval_tf2.py predicted-frames-final_result-test.pkl gesture_rnn.model

# 8. 测试单个视频
python predict_video.py test_videos/Hello/test_hello_001.mp4
```

---

## 🎯 快速命令参考

### ⚡ 完整重训练 - 不备份版本（最简单）

**适用于：不需要保留旧模型，直接覆盖训练**

```powershell
# 1. 清理旧数据（只需删除帧和特征文件，模型会自动覆盖）
Remove-Item -Recurse -Force train_frames -ErrorAction SilentlyContinue
Remove-Item -Recurse -Force test_frames -ErrorAction SilentlyContinue
Remove-Item predicted-frames-*.pkl -ErrorAction SilentlyContinue

# 2. 提取帧
python video-to-frame.py train_videos train_frames
python video-to-frame.py test_videos test_frames

# 3. 训练CNN（会自动覆盖 gesture_model_best.h5）
python retrain_tf2.py --image_dir train_frames --epochs 15

# 4. 提取特征
python predict_spatial_tf2.py gesture_model_best.h5 train_frames --batch_size 100
python predict_spatial_tf2.py gesture_model_best.h5 test_frames --batch_size 100 --test

# 5. 训练RNN（会自动覆盖 checkpoints/gesture_rnn.h5）
python rnn_train_tf2.py predicted-frames-final_result-train.pkl gesture_rnn.model --batch_size 32 --epochs 20

# 6. 评估
python rnn_eval_tf2.py predicted-frames-final_result-test.pkl gesture_rnn.model
```

### 🛡️ 完整重训练 - 备份版本（谨慎用户）

**适用于：想保留旧模型作为备份**

```powershell
# 1. 备份旧模型
mkdir models_backup -ErrorAction SilentlyContinue
Copy-Item gesture_model_best.h5 models_backup/gesture_model_best_backup.h5 -ErrorAction SilentlyContinue
Copy-Item checkpoints/gesture_rnn.h5 models_backup/gesture_rnn_backup.h5 -ErrorAction SilentlyContinue
Copy-Item retrained_labels.txt models_backup/retrained_labels_backup.txt -ErrorAction SilentlyContinue

# 2. 清理旧数据
Remove-Item -Recurse -Force train_frames -ErrorAction SilentlyContinue
Remove-Item -Recurse -Force test_frames -ErrorAction SilentlyContinue
Remove-Item predicted-frames-*.pkl -ErrorAction SilentlyContinue

# 3-6. 执行上面"不备份版本"的步骤 2-6
```

---

## 💡 优化建议

### 提高模型性能

1. **数据质量优先**

   - 确保视频光线充足
   - 手势完整清晰
   - 背景简洁

2. **足够的训练样本**

   - 每个类别至少 5-10 个训练视频
   - 每个类别至少 2-3 个测试视频

3. **数据多样性**

   - 不同的人表演相同手势
   - 不同的光线条件
   - 不同的角度和距离

4. **超参数调优**
   - 如果准确率不理想，增加训练轮数 (epochs 20-30)
   - 如果过拟合，减少训练轮数或增加 dropout
   - 调整批大小适应您的硬件

---

## ✅ 检查清单

重新训练前：

- [ ] 已准备好训练和测试视频
- [ ] 视频按类别正确组织在文件夹中
- [ ] 每个类别有足够的样本
- [ ] 已备份旧模型（如需要）

重新训练后：

- [ ] 检查训练准确率 (>90%)
- [ ] 检查验证准确率 (>85%)
- [ ] 运行测试评估
- [ ] 测试几个单独的视频
- [ ] 查看 results.txt 了解详细结果
- [ ] 确认所有类别都能正确识别

---

## 📞 需要帮助？

如果遇到问题：

1. 检查错误信息
2. 确认数据文件夹结构正确
3. 确认所有依赖已安装
4. 查看 `使用指南.md` 获取更多信息

**祝您训练顺利！** 🎉
