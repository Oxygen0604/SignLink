# æ‰‹è¯­æ‰‹åŠ¿è¯†åˆ«ç³»ç»Ÿ - ä½¿ç”¨æŒ‡å—

## ğŸ¯ é¡¹ç›®ç®€ä»‹

è¿™æ˜¯ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„æ‰‹è¯­æ‰‹åŠ¿è¯†åˆ«ç³»ç»Ÿ,ä½¿ç”¨ CNN+RNN æ¶æ„æ¥è¯†åˆ«è§†é¢‘ä¸­çš„æ‰‹è¯­æ‰‹åŠ¿ã€‚

## âœ… å·²å®Œæˆçš„å·¥ä½œ

1. âœ… å®‰è£…æ‰€æœ‰å¿…éœ€çš„ä¾èµ–
2. âœ… ä»è§†é¢‘ä¸­æå–å¸§å¹¶è¿›è¡Œæ‰‹éƒ¨åˆ†å‰²
3. âœ… è®­ç»ƒ CNN æ¨¡å‹(MobileNetV2)è¿›è¡Œç©ºé—´ç‰¹å¾æå–
4. âœ… ä½¿ç”¨ CNN æå–è§†é¢‘å¸§çš„ç‰¹å¾
5. âœ… è®­ç»ƒ RNN æ¨¡å‹(LSTM)è¿›è¡Œæ—¶åºå»ºæ¨¡
6. âœ… åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹å¹¶è¾¾åˆ° 100%å‡†ç¡®ç‡

## ğŸ“Š æ¨¡å‹æ€§èƒ½

- **CNN æ¨¡å‹**: éªŒè¯å‡†ç¡®ç‡ 100%
- **RNN æ¨¡å‹**: éªŒè¯å‡†ç¡®ç‡ 100%
- **æµ‹è¯•é›†å‡†ç¡®ç‡**: 100% (6/6 ä¸ªè§†é¢‘å…¨éƒ¨é¢„æµ‹æ­£ç¡®)

## ğŸ“ é‡è¦æ–‡ä»¶è¯´æ˜

### æ¨¡å‹æ–‡ä»¶

- `gesture_model_best.h5` - è®­ç»ƒå¥½çš„ CNN æ¨¡å‹
- `checkpoints/gesture_rnn.h5` - è®­ç»ƒå¥½çš„ RNN æ¨¡å‹
- `retrained_labels.txt` - ç±»åˆ«æ ‡ç­¾æ–‡ä»¶

### æ•°æ®æ–‡ä»¶

- `train_frames/` - è®­ç»ƒè§†é¢‘çš„å¸§
- `test_frames/` - æµ‹è¯•è§†é¢‘çš„å¸§
- `predicted-frames-final_result-train.pkl` - è®­ç»ƒç‰¹å¾
- `predicted-frames-final_result-test.pkl` - æµ‹è¯•ç‰¹å¾

### è„šæœ¬æ–‡ä»¶ï¼ˆTensorFlow 2.x ç‰ˆæœ¬ï¼‰

- `retrain_tf2.py` - è®­ç»ƒ CNN æ¨¡å‹
- `predict_spatial_tf2.py` - æå–è§†é¢‘å¸§ç‰¹å¾
- `rnn_train_tf2.py` - è®­ç»ƒ RNN æ¨¡å‹
- `rnn_eval_tf2.py` - è¯„ä¼° RNN æ¨¡å‹
- `predict_video.py` - **å¯¹æ–°è§†é¢‘è¿›è¡Œé¢„æµ‹ï¼ˆæ¨ç†è„šæœ¬ï¼‰**

## ğŸš€ å¦‚ä½•ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹

### å¯¹æ–°è§†é¢‘è¿›è¡Œé¢„æµ‹

```bash
python predict_video.py <è§†é¢‘æ–‡ä»¶è·¯å¾„>
```

**ç¤ºä¾‹:**

```bash
# é¢„æµ‹Acceptæ‰‹åŠ¿
python predict_video.py test_videos/Accept/050_010_001.mp4

# é¢„æµ‹Appearæ‰‹åŠ¿
python predict_video.py test_videos/Appear/053_010_001.mp4
```

**è¾“å‡ºç¤ºä¾‹:**

```
ç±»åˆ«: ['Accept', 'Appear']

åŠ è½½CNNæ¨¡å‹...
åŠ è½½RNNæ¨¡å‹...

ä»è§†é¢‘æå–å¸§: test_videos/Accept/050_010_001.mp4
æå–äº† 201 å¸§
é¢„å¤„ç†å¸§...
ä½¿ç”¨CNNæå–ç‰¹å¾...
ä½¿ç”¨RNNè¿›è¡Œé¢„æµ‹...

==================================================
é¢„æµ‹ç»“æœ:
==================================================
æ‰‹åŠ¿: Accept
ç½®ä¿¡åº¦: 0.5195
==================================================

æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡:
  Accept: 0.5195
  Appear: 0.4805
```

## ğŸ”„ å¦‚ä½•é‡æ–°è®­ç»ƒæ¨¡å‹

å¦‚æœæ‚¨æƒ³ç”¨æ–°æ•°æ®é‡æ–°è®­ç»ƒæ¨¡å‹,è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œ:

### æ­¥éª¤ 1: å‡†å¤‡æ•°æ®

å°†è§†é¢‘æŒ‰ç±»åˆ«æ”¾å…¥`train_videos`å’Œ`test_videos`æ–‡ä»¶å¤¹:

```
train_videos/
â”œâ”€â”€ ç±»åˆ«1/
â”‚   â”œâ”€â”€ video1.mp4
â”‚   â”œâ”€â”€ video2.mp4
â”‚   â””â”€â”€ ...
â””â”€â”€ ç±»åˆ«2/
    â”œâ”€â”€ video1.mp4
    â””â”€â”€ ...
```

### æ­¥éª¤ 2: æå–å¸§

```bash
python video-to-frame.py train_videos train_frames
python video-to-frame.py test_videos test_frames
```

### æ­¥éª¤ 3: è®­ç»ƒ CNN æ¨¡å‹

```bash
python retrain_tf2.py --image_dir train_frames --epochs 15
```

### æ­¥éª¤ 4: æå–ç‰¹å¾

```bash
# è®­ç»ƒé›†
python predict_spatial_tf2.py gesture_model_best.h5 train_frames --batch_size 100

# æµ‹è¯•é›†
python predict_spatial_tf2.py gesture_model_best.h5 test_frames --batch_size 100 --test
```

### æ­¥éª¤ 5: è®­ç»ƒ RNN æ¨¡å‹

```bash
python rnn_train_tf2.py predicted-frames-final_result-train.pkl gesture_rnn.model --batch_size 32 --epochs 20
```

### æ­¥éª¤ 6: è¯„ä¼°æ¨¡å‹

```bash
python rnn_eval_tf2.py predicted-frames-final_result-test.pkl gesture_rnn.model
```

## ğŸ“¦ ä¾èµ–é¡¹

æ‰€æœ‰ä¾èµ–å·²å®‰è£…åœ¨`requirements.txt`ä¸­:

```
opencv-python
opencv-contrib-python
tensorflow
numpy
scikit-learn
tqdm
h5py
```

## ğŸ’¡ æç¤ºå’Œå»ºè®®

### æé«˜æ¨¡å‹æ€§èƒ½

1. **å¢åŠ è®­ç»ƒæ•°æ®** - æ›´å¤šçš„è§†é¢‘æ ·æœ¬å¯ä»¥æé«˜æ³›åŒ–èƒ½åŠ›
2. **æ•°æ®å¢å¼º** - å¯¹è§†é¢‘è¿›è¡Œæ—‹è½¬ã€ç¼©æ”¾ã€äº®åº¦è°ƒæ•´ç­‰
3. **è°ƒæ•´è¶…å‚æ•°** - å°è¯•ä¸åŒçš„å­¦ä¹ ç‡ã€æ‰¹å¤§å°ã€epoch æ•°
4. **å°è¯•ä¸åŒæ¶æ„** - å¯ä»¥å°è¯• Inception V3 æˆ– ResNet ä½œä¸ºç‰¹å¾æå–å™¨

### ä½¿ç”¨ä¸åŒçš„æ¨¡å‹æ¶æ„

RNN è®­ç»ƒè„šæœ¬æ”¯æŒä¸‰ç§æ¶æ„:

```bash
# é»˜è®¤æ¶æ„
python rnn_train_tf2.py ... --model_type default

# å®½LSTM (æ¨è)
python rnn_train_tf2.py ... --model_type wide

# æ·±LSTM
python rnn_train_tf2.py ... --model_type deep
```

### ä½¿ç”¨ç‰¹å¾å±‚è€Œé Softmax

å¦‚æœæƒ³ä½¿ç”¨ CNN çš„ç‰¹å¾å±‚(è€Œä¸æ˜¯ softmax è¾“å‡º):

```bash
python predict_spatial_tf2.py gesture_model_best.h5 train_frames --use_features
```

## ğŸ” æŸ¥çœ‹ç»“æœ

- è®­ç»ƒè¿‡ç¨‹çš„è¯¦ç»†ä¿¡æ¯ä¿å­˜åœ¨ç»ˆç«¯è¾“å‡ºä¸­
- æµ‹è¯•ç»“æœä¿å­˜åœ¨`results.txt`æ–‡ä»¶ä¸­
- å®Œæ•´çš„è®­ç»ƒæ€»ç»“åœ¨`TRAINING_SUMMARY.md`ä¸­

## â“ å¸¸è§é—®é¢˜

**Q: ä¸ºä»€ä¹ˆæœ‰ä¸¤å¥—è„šæœ¬(åŸå§‹çš„å’Œ tf2 ç‰ˆæœ¬)?**
A: åŸå§‹è„šæœ¬ä½¿ç”¨ TFLearn,ä¸ TensorFlow 2.x ä¸å…¼å®¹ã€‚æˆ‘åˆ›å»ºäº†æ–°çš„ tf2 ç‰ˆæœ¬è„šæœ¬æ¥æ›¿ä»£å®ƒä»¬ã€‚

**Q: èƒ½è¯†åˆ«å¤šå°‘ç§æ‰‹åŠ¿?**
A: å½“å‰æ¨¡å‹è®­ç»ƒäº† 2 ç§æ‰‹åŠ¿(Accept å’Œ Appear)ã€‚æ‚¨å¯ä»¥é€šè¿‡æ·»åŠ æ›´å¤šç±»åˆ«çš„è®­ç»ƒæ•°æ®æ¥æ‰©å±•ã€‚

**Q: é¢„æµ‹ä¸€ä¸ªè§†é¢‘éœ€è¦å¤šé•¿æ—¶é—´?**
A: åœ¨ CPU ä¸Šå¤§çº¦éœ€è¦ 10-15 ç§’,åŒ…æ‹¬å¸§æå–ã€ç‰¹å¾æå–å’Œé¢„æµ‹ã€‚

**Q: å¦‚ä½•æ·»åŠ æ–°çš„æ‰‹åŠ¿ç±»åˆ«?**
A: åœ¨`train_videos`å’Œ`test_videos`ä¸­åˆ›å»ºæ–°çš„æ–‡ä»¶å¤¹,æ”¾å…¥ç›¸åº”çš„è§†é¢‘,ç„¶åé‡æ–°è®­ç»ƒæ¨¡å‹ã€‚

## ğŸ“ æŠ€æœ¯ç»†èŠ‚

### æ¨¡å‹æ¶æ„

1. **ç©ºé—´ç‰¹å¾æå–**: MobileNetV2 â†’ æ¯å¸§æå– 2 ç»´ softmax æ¦‚ç‡
2. **æ—¶åºå»ºæ¨¡**: LSTM(256 å•å…ƒ) â†’ å­¦ä¹  201 å¸§çš„æ—¶åºå…³ç³»
3. **åˆ†ç±»**: å…¨è¿æ¥å±‚ â†’ è¾“å‡ºæœ€ç»ˆæ‰‹åŠ¿ç±»åˆ«

### æ•°æ®æµç¨‹

```
è§†é¢‘ â†’ å¸§æå–(201å¸§) â†’ CNNç‰¹å¾æå– â†’ RNNæ—¶åºå»ºæ¨¡ â†’ é¢„æµ‹ç»“æœ
```

## ğŸ‰ æˆåŠŸæ¡ˆä¾‹

æµ‹è¯•é›†æ‰€æœ‰ 6 ä¸ªè§†é¢‘å…¨éƒ¨æ­£ç¡®è¯†åˆ«:

- Accept ç±»åˆ«: 3/3 æ­£ç¡®
- Appear ç±»åˆ«: 3/3 æ­£ç¡®

## ğŸ“§ è”ç³»ä¸æ”¯æŒ

å¦‚æœ‰é—®é¢˜,è¯·å‚è€ƒ:

- åŸå§‹è®ºæ–‡: https://link.springer.com/chapter/10.1007/978-981-10-7566-7_63
- GitHub ä»“åº“: https://github.com/hthuwal/sign-language-gesture-recognition

---

**ç¥æ‚¨ä½¿ç”¨æ„‰å¿«!** ğŸŠ
