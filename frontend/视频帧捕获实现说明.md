# 视频帧捕获实现说明

## 概述

本文档说明如何在 React Native 中从摄像头获取视频帧，转换为 Base64 格式，并通过 WebSocket 或 HTTP API 传输图像数据到后端。

## 实现方案

### 1. 视频帧捕获

#### Web 环境
- 使用 **ImageCapture API**（如果支持）
- 或使用 **Video 元素 + Canvas API** 捕获帧

#### React Native 环境
- 使用 **react-native-view-shot** 从 RTCView 截图
- **注意**：react-native-view-shot 可能无法直接捕获 RTCView（原生视图）
- 如果失败，可以使用 HTTP API 作为后备方案

### 2. 数据传输

#### 优先使用 WebSocket
- 实时双向通信
- 低延迟
- 适合实时视频流处理

#### 后备使用 HTTP API
- WebSocket 不可用时自动切换
- 使用 POST 请求上传图像
- 获取识别结果并更新状态

## 使用方法

### 1. 安装依赖

```bash
npm install react-native-view-shot react-native-fs
```

### 2. iOS 配置

在 `Info.plist` 中添加摄像头权限：

```xml
<key>NSCameraUsageDescription</key>
<string>应用需要访问您的摄像头以进行手语翻译</string>
```

### 3. Android 配置

在 `AndroidManifest.xml` 中添加摄像头权限：

```xml
<uses-permission android:name="android.permission.CAMERA" />
```

### 4. 代码使用

代码已经集成在 `SignHomeScreen.ios.tsx` 和 `SignHomeScreen.android.tsx` 中：

- 自动启动摄像头
- 自动连接 WebSocket
- 每 200ms 捕获一帧并发送
- 自动接收识别结果并更新 UI

## 工作原理

### 1. 视频帧捕获流程

```
摄像头启动 → 获取 MediaStream → 创建 RTCView → 捕获帧 → 转换为 Base64
```

### 2. 数据传输流程

```
捕获帧 → 转换为 Base64 → 通过 WebSocket 发送 → 后端识别 → 返回结果 → 更新 UI
```

如果 WebSocket 不可用：

```
捕获帧 → 转换为 Base64 → 通过 HTTP API 发送 → 后端识别 → 返回结果 → 更新 UI
```

## 配置说明

### 1. WebSocket 地址

在 `frontend/src/store/translationStore.ts` 中修改：

```typescript
const WS_URL = 'ws://localhost:5000/ws/translation'; // 修改为实际地址
```

### 2. HTTP API 地址

在 `frontend/src/store/translationStore.ts` 中修改：

```typescript
const HTTP_API_URL = 'http://localhost:5000/api/recognize/realtime'; // 修改为实际地址
```

### 3. 捕获频率

在 `SignHomeScreen.ios.tsx` 或 `SignHomeScreen.android.tsx` 中修改：

```typescript
}, 200); // 每200ms捕获一帧，可根据需要调整
```

## 故障排查

### 1. 无法捕获帧

**问题**：react-native-view-shot 无法捕获 RTCView

**解决方案**：
1. 使用 HTTP API 作为后备方案（已实现）
2. 创建原生模块从 VideoTrack 捕获帧
3. 使用 react-native-vision-camera 替代 react-native-webrtc

### 2. WebSocket 连接失败

**问题**：WebSocket 无法连接

**解决方案**：
1. 检查后端服务是否运行
2. 检查 WebSocket 地址是否正确
3. 自动切换到 HTTP API（已实现）

### 3. 性能问题

**问题**：捕获帧导致性能下降

**解决方案**：
1. 减少捕获频率（例如每 500ms 一次）
2. 降低图像质量（quality: 0.6）
3. 缩小图像尺寸
4. 使用原生模块（性能最佳）

## 注意事项

1. **react-native-view-shot 限制**：
   - 可能无法直接捕获 RTCView
   - 如果失败，会自动使用 HTTP API

2. **性能优化**：
   - 建议捕获频率不超过每 200ms 一次
   - 可以根据网络情况调整频率
   - 考虑压缩图像大小

3. **内存管理**：
   - 及时清理定时器
   - 避免内存泄漏
   - 注意 Base64 数据大小

4. **错误处理**：
   - 处理捕获失败的情况
   - 处理 WebSocket 连接失败的情况
   - 添加重试机制（已实现）

## 后续优化建议

1. **创建原生模块**：
   - 直接从 VideoTrack 捕获帧
   - 性能最佳
   - 需要原生开发经验

2. **使用 react-native-vision-camera**：
   - 提供更好的性能
   - 支持帧处理器
   - 需要重构代码

3. **图像压缩**：
   - 在发送前压缩图像
   - 减少传输数据量
   - 提高性能

4. **批量发送**：
   - 收集多帧后批量发送
   - 减少网络请求
   - 提高效率

## 测试建议

1. **测试 WebSocket 连接**：
   - 检查连接是否正常
   - 检查消息是否正常接收

2. **测试 HTTP API**：
   - 检查 WebSocket 不可用时是否自动切换
   - 检查识别结果是否正常更新

3. **测试性能**：
   - 检查捕获频率是否合适
   - 检查内存使用情况
   - 检查网络流量

4. **测试错误处理**：
   - 测试网络断开情况
   - 测试后端服务不可用情况
   - 测试权限被拒绝情况

